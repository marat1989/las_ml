{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kgl</th>\n",
       "      <th>wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.2271827161, 0.2292189108184549, 0.226675257...</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.3963141739, 0.39631417390000007, 0.40498641...</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.2935534418, 0.3053143287430829, 0.303001516...</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.3775226176, 0.3775226176, 0.354627072799999...</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.147988826, 0.17931516317458643, 0.208930206...</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 kgl    wc\n",
       "0  [0.2271827161, 0.2292189108184549, 0.226675257...  0.22\n",
       "1  [0.3963141739, 0.39631417390000007, 0.40498641...  0.39\n",
       "2  [0.2935534418, 0.3053143287430829, 0.303001516...  0.38\n",
       "3  [0.3775226176, 0.3775226176, 0.354627072799999...  0.31\n",
       "4  [0.147988826, 0.17931516317458643, 0.208930206...  0.39"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_las_kgl = pd.read_csv('fake_data/fake_data_collect_kgl.csv', delimiter=';')\n",
    "del fake_las_kgl['Unnamed: 0']\n",
    "fake_las_kgl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_las_kgl.replace(',', ';', regex=True, inplace=True)\n",
    "fake_las_kgl.to_csv('fake_data/fake_data_collect_kgl_1.csv', index=False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227183</td>\n",
       "      <td>0.229219</td>\n",
       "      <td>0.226675</td>\n",
       "      <td>0.216163</td>\n",
       "      <td>0.123856</td>\n",
       "      <td>0.122162</td>\n",
       "      <td>0.124524</td>\n",
       "      <td>0.121009</td>\n",
       "      <td>0.115269</td>\n",
       "      <td>0.122897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100685</td>\n",
       "      <td>0.107715</td>\n",
       "      <td>0.117733</td>\n",
       "      <td>0.119287</td>\n",
       "      <td>0.108693</td>\n",
       "      <td>0.114867</td>\n",
       "      <td>0.147499</td>\n",
       "      <td>0.131292</td>\n",
       "      <td>0.114781</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.396314</td>\n",
       "      <td>0.396314</td>\n",
       "      <td>0.404986</td>\n",
       "      <td>0.305105</td>\n",
       "      <td>0.268331</td>\n",
       "      <td>0.292826</td>\n",
       "      <td>0.262488</td>\n",
       "      <td>0.282108</td>\n",
       "      <td>0.299649</td>\n",
       "      <td>0.277263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134884</td>\n",
       "      <td>0.121387</td>\n",
       "      <td>0.094553</td>\n",
       "      <td>0.120820</td>\n",
       "      <td>0.347750</td>\n",
       "      <td>0.364641</td>\n",
       "      <td>0.353523</td>\n",
       "      <td>0.336004</td>\n",
       "      <td>0.416229</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.293553</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.303002</td>\n",
       "      <td>0.308562</td>\n",
       "      <td>0.310217</td>\n",
       "      <td>0.304514</td>\n",
       "      <td>0.310325</td>\n",
       "      <td>0.327548</td>\n",
       "      <td>0.289342</td>\n",
       "      <td>0.289983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421735</td>\n",
       "      <td>0.435352</td>\n",
       "      <td>0.437670</td>\n",
       "      <td>0.434946</td>\n",
       "      <td>0.434682</td>\n",
       "      <td>0.432638</td>\n",
       "      <td>0.416016</td>\n",
       "      <td>0.415558</td>\n",
       "      <td>0.420287</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377523</td>\n",
       "      <td>0.377523</td>\n",
       "      <td>0.354627</td>\n",
       "      <td>0.357531</td>\n",
       "      <td>0.360867</td>\n",
       "      <td>0.344058</td>\n",
       "      <td>0.333473</td>\n",
       "      <td>0.340105</td>\n",
       "      <td>0.348635</td>\n",
       "      <td>0.345380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257030</td>\n",
       "      <td>0.288878</td>\n",
       "      <td>0.292152</td>\n",
       "      <td>0.292536</td>\n",
       "      <td>0.296641</td>\n",
       "      <td>0.307266</td>\n",
       "      <td>0.287952</td>\n",
       "      <td>0.315756</td>\n",
       "      <td>0.313107</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147989</td>\n",
       "      <td>0.179315</td>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>0.197656</td>\n",
       "      <td>0.182883</td>\n",
       "      <td>0.177504</td>\n",
       "      <td>0.179439</td>\n",
       "      <td>0.207470</td>\n",
       "      <td>0.203137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224901</td>\n",
       "      <td>0.226155</td>\n",
       "      <td>0.237325</td>\n",
       "      <td>0.161780</td>\n",
       "      <td>0.141492</td>\n",
       "      <td>0.140836</td>\n",
       "      <td>0.125245</td>\n",
       "      <td>0.129295</td>\n",
       "      <td>0.129360</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.227183  0.229219  0.226675  0.216163  0.123856  0.122162  0.124524   \n",
       "1  0.396314  0.396314  0.404986  0.305105  0.268331  0.292826  0.262488   \n",
       "2  0.293553  0.305314  0.303002  0.308562  0.310217  0.304514  0.310325   \n",
       "3  0.377523  0.377523  0.354627  0.357531  0.360867  0.344058  0.333473   \n",
       "4  0.147989  0.179315  0.208930  0.222672  0.197656  0.182883  0.177504   \n",
       "\n",
       "          7         8         9  ...         91        92        93        94  \\\n",
       "0  0.121009  0.115269  0.122897  ...   0.100685  0.107715  0.117733  0.119287   \n",
       "1  0.282108  0.299649  0.277263  ...   0.134884  0.121387  0.094553  0.120820   \n",
       "2  0.327548  0.289342  0.289983  ...   0.421735  0.435352  0.437670  0.434946   \n",
       "3  0.340105  0.348635  0.345380  ...   0.257030  0.288878  0.292152  0.292536   \n",
       "4  0.179439  0.207470  0.203137  ...   0.224901  0.226155  0.237325  0.161780   \n",
       "\n",
       "         95        96        97        98        99    wc  \n",
       "0  0.108693  0.114867  0.147499  0.131292  0.114781  0.22  \n",
       "1  0.347750  0.364641  0.353523  0.336004  0.416229  0.39  \n",
       "2  0.434682  0.432638  0.416016  0.415558  0.420287  0.38  \n",
       "3  0.296641  0.307266  0.287952  0.315756  0.313107  0.31  \n",
       "4  0.141492  0.140836  0.125245  0.129295  0.129360  0.39  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_las_kgl = pd.read_csv('fake_data/fake_data_collect_kgl_1.csv', delimiter=';', header=None)\n",
    "fake_las_kgl = fake_las_kgl.rename(columns={100: \"wc\"})\n",
    "fake_las_kgl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5322,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values = fake_las_kgl['wc']\n",
    "y_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5322, 100)\n"
     ]
    }
   ],
   "source": [
    "del fake_las_kgl['wc']\n",
    "x_values = np.array(fake_las_kgl)\n",
    "print(x_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "x_train, x_hold, y_train, y_hold = train_test_split(x_values, y_values, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13\n",
      "0.62\n",
      "0.49\n"
     ]
    }
   ],
   "source": [
    "print(min(y_values))\n",
    "print(max(y_values))\n",
    "print(max(y_values) - min(y_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 250)               25250     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               25100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 49)                4949      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 50        \n",
      "=================================================================\n",
      "Total params: 75,549\n",
      "Trainable params: 75,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Устанавливаем seed для повторяемости результатов\n",
    "np.random.seed(42)\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(250, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(250,)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(100,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dense(49, activation='relu', input_shape=(100,)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Компилируем модель\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mae'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M1\\Anaconda3\\lib\\site-packages\\keras\\models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3725/3725 [==============================] - 2s 515us/step - loss: 0.0061 - mean_absolute_error: 0.0597\n",
      "Epoch 2/50\n",
      "3725/3725 [==============================] - 1s 380us/step - loss: 0.0043 - mean_absolute_error: 0.0510\n",
      "Epoch 3/50\n",
      "3725/3725 [==============================] - 1s 373us/step - loss: 0.0040 - mean_absolute_error: 0.0488\n",
      "Epoch 4/50\n",
      "3725/3725 [==============================] - 1s 383us/step - loss: 0.0036 - mean_absolute_error: 0.0461\n",
      "Epoch 5/50\n",
      "3725/3725 [==============================] - 1s 392us/step - loss: 0.0034 - mean_absolute_error: 0.0443\n",
      "Epoch 6/50\n",
      "3725/3725 [==============================] - 2s 405us/step - loss: 0.0032 - mean_absolute_error: 0.0422\n",
      "Epoch 7/50\n",
      "3725/3725 [==============================] - 2s 412us/step - loss: 0.0030 - mean_absolute_error: 0.0410\n",
      "Epoch 8/50\n",
      "3725/3725 [==============================] - 2s 428us/step - loss: 0.0027 - mean_absolute_error: 0.0390\n",
      "Epoch 9/50\n",
      "3725/3725 [==============================] - 2s 499us/step - loss: 0.0027 - mean_absolute_error: 0.0390\n",
      "Epoch 10/50\n",
      "3725/3725 [==============================] - 1s 382us/step - loss: 0.0025 - mean_absolute_error: 0.0368\n",
      "Epoch 11/50\n",
      "3725/3725 [==============================] - 1s 395us/step - loss: 0.0025 - mean_absolute_error: 0.0375\n",
      "Epoch 12/50\n",
      "3725/3725 [==============================] - 1s 398us/step - loss: 0.0023 - mean_absolute_error: 0.0357\n",
      "Epoch 13/50\n",
      "3725/3725 [==============================] - 2s 407us/step - loss: 0.0024 - mean_absolute_error: 0.0360\n",
      "Epoch 14/50\n",
      "3725/3725 [==============================] - 1s 402us/step - loss: 0.0023 - mean_absolute_error: 0.0353\n",
      "Epoch 15/50\n",
      "3725/3725 [==============================] - 2s 422us/step - loss: 0.0021 - mean_absolute_error: 0.0338\n",
      "Epoch 16/50\n",
      "3725/3725 [==============================] - 2s 431us/step - loss: 0.0023 - mean_absolute_error: 0.0348\n",
      "Epoch 17/50\n",
      "3725/3725 [==============================] - 2s 421us/step - loss: 0.0019 - mean_absolute_error: 0.0321\n",
      "Epoch 18/50\n",
      "3725/3725 [==============================] - 2s 433us/step - loss: 0.0020 - mean_absolute_error: 0.0322\n",
      "Epoch 19/50\n",
      "3725/3725 [==============================] - 2s 424us/step - loss: 0.0018 - mean_absolute_error: 0.0313\n",
      "Epoch 20/50\n",
      "3725/3725 [==============================] - 2s 435us/step - loss: 0.0019 - mean_absolute_error: 0.0315\n",
      "Epoch 21/50\n",
      "3725/3725 [==============================] - 2s 413us/step - loss: 0.0019 - mean_absolute_error: 0.0318\n",
      "Epoch 22/50\n",
      "3725/3725 [==============================] - 2s 435us/step - loss: 0.0017 - mean_absolute_error: 0.0298\n",
      "Epoch 23/50\n",
      "3725/3725 [==============================] - 2s 424us/step - loss: 0.0017 - mean_absolute_error: 0.0294\n",
      "Epoch 24/50\n",
      "3725/3725 [==============================] - 2s 444us/step - loss: 0.0016 - mean_absolute_error: 0.0291\n",
      "Epoch 25/50\n",
      "3725/3725 [==============================] - 2s 453us/step - loss: 0.0018 - mean_absolute_error: 0.0306\n",
      "Epoch 26/50\n",
      "3725/3725 [==============================] - 2s 452us/step - loss: 0.0016 - mean_absolute_error: 0.0287\n",
      "Epoch 27/50\n",
      "3725/3725 [==============================] - 2s 448us/step - loss: 0.0017 - mean_absolute_error: 0.0290\n",
      "Epoch 28/50\n",
      "3725/3725 [==============================] - 2s 442us/step - loss: 0.0015 - mean_absolute_error: 0.0275\n",
      "Epoch 29/50\n",
      "3725/3725 [==============================] - 2s 479us/step - loss: 0.0015 - mean_absolute_error: 0.0272\n",
      "Epoch 30/50\n",
      "3725/3725 [==============================] - 2s 441us/step - loss: 0.0015 - mean_absolute_error: 0.0278\n",
      "Epoch 31/50\n",
      "3725/3725 [==============================] - 2s 440us/step - loss: 0.0015 - mean_absolute_error: 0.0275\n",
      "Epoch 32/50\n",
      "3725/3725 [==============================] - 2s 443us/step - loss: 0.0014 - mean_absolute_error: 0.0264\n",
      "Epoch 33/50\n",
      "3725/3725 [==============================] - 2s 434us/step - loss: 0.0013 - mean_absolute_error: 0.0258\n",
      "Epoch 34/50\n",
      "3725/3725 [==============================] - 2s 455us/step - loss: 0.0017 - mean_absolute_error: 0.0287\n",
      "Epoch 35/50\n",
      "3725/3725 [==============================] - 2s 541us/step - loss: 0.0014 - mean_absolute_error: 0.0259\n",
      "Epoch 36/50\n",
      "3725/3725 [==============================] - 2s 547us/step - loss: 0.0013 - mean_absolute_error: 0.0256 1s - loss: 0.0015 - mean_a\n",
      "Epoch 37/50\n",
      "3725/3725 [==============================] - 2s 480us/step - loss: 0.0013 - mean_absolute_error: 0.0252\n",
      "Epoch 38/50\n",
      "3725/3725 [==============================] - 2s 508us/step - loss: 0.0012 - mean_absolute_error: 0.0249\n",
      "Epoch 39/50\n",
      "3725/3725 [==============================] - 2s 487us/step - loss: 0.0014 - mean_absolute_error: 0.0256\n",
      "Epoch 40/50\n",
      "3725/3725 [==============================] - 2s 535us/step - loss: 0.0014 - mean_absolute_error: 0.0260\n",
      "Epoch 41/50\n",
      "3725/3725 [==============================] - 2s 503us/step - loss: 0.0011 - mean_absolute_error: 0.0234\n",
      "Epoch 42/50\n",
      "3725/3725 [==============================] - 2s 499us/step - loss: 0.0012 - mean_absolute_error: 0.0242\n",
      "Epoch 43/50\n",
      "3725/3725 [==============================] - 2s 511us/step - loss: 0.0012 - mean_absolute_error: 0.0238\n",
      "Epoch 44/50\n",
      "3725/3725 [==============================] - 2s 472us/step - loss: 0.0013 - mean_absolute_error: 0.0250\n",
      "Epoch 45/50\n",
      "3725/3725 [==============================] - 2s 467us/step - loss: 0.0010 - mean_absolute_error: 0.0224\n",
      "Epoch 46/50\n",
      "3725/3725 [==============================] - 2s 478us/step - loss: 0.0011 - mean_absolute_error: 0.0231\n",
      "Epoch 47/50\n",
      "3725/3725 [==============================] - 2s 491us/step - loss: 0.0012 - mean_absolute_error: 0.0240\n",
      "Epoch 48/50\n",
      "3725/3725 [==============================] - 2s 508us/step - loss: 9.7401e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 49/50\n",
      "3725/3725 [==============================] - 2s 486us/step - loss: 9.5778e-04 - mean_absolute_error: 0.0216\n",
      "Epoch 50/50\n",
      "3725/3725 [==============================] - 2s 493us/step - loss: 0.0011 - mean_absolute_error: 0.0225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a67da0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем сеть\n",
    "model.fit(x_train, y_train, batch_size=5, nb_epoch=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "def data_analize_func(predict_for_analize, file_name = ''):\n",
    "    # подготовка данных\n",
    "    data_for_analize = predict_for_analize.sort_values(by=['y_hold'])\n",
    "    data_for_analize['x_axis'] = [x for x in range(len(predict_for_analize['y_hold']))]\n",
    "    data_for_analize.head()\n",
    "    if file_name != '':\n",
    "        data_for_analize.to_csv('AllGisParams/' + file_name, index=False, sep = ';')\n",
    "    \n",
    "    # построение графиков\n",
    "    plt.scatter(data_for_analize['x_axis'], data_for_analize['y_predict'], color = 'blue')\n",
    "    plt.scatter(data_for_analize['x_axis'], data_for_analize['y_hold'], color = 'red')\n",
    "    plt.show()\n",
    "    \n",
    "    # regression metrics\n",
    "    print('MSE                      = '+ str(mean_squared_error(data_for_analize['y_hold'], \n",
    "                                                                data_for_analize['y_predict'])))\n",
    "    print('MAE                      = '+ str(mean_absolute_error(data_for_analize['y_hold'], \n",
    "                                                                 data_for_analize['y_predict'])))\n",
    "    print('r2_score                 = '+ str(r2_score(data_for_analize['y_hold'], \n",
    "                                                      data_for_analize['y_predict'])) + '    (best_value is 1)')\n",
    "    print('explained_variance_score = '+ str(explained_variance_score(data_for_analize['y_hold'], \n",
    "                                                                      data_for_analize['y_predict'])) + '    (best_value is 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185ef400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE                      = 0.00104373073535\n",
      "MAE                      = 0.0229076304138\n",
      "r2_score                 = 0.787877068048    (best_value is 1)\n",
      "explained_variance_score = 0.78907623941    (best_value is 1)\n"
     ]
    }
   ],
   "source": [
    "predict_for_analize_fake = pd.DataFrame({'y_hold':y_hold, 'y_predict':y_predict[:,0]})\n",
    "data_analize_func(predict_for_analize_fake)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
