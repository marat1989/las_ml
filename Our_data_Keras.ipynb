{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_name</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>aps</th>\n",
       "      <th>rp</th>\n",
       "      <th>kp</th>\n",
       "      <th>kgl</th>\n",
       "      <th>kpr</th>\n",
       "      <th>kvo</th>\n",
       "      <th>kng</th>\n",
       "      <th>lit</th>\n",
       "      <th>satur</th>\n",
       "      <th>wc</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198</td>\n",
       "      <td>3116.2</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>354107.28</td>\n",
       "      <td>6462246.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198</td>\n",
       "      <td>3116.3</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>354107.28</td>\n",
       "      <td>6462246.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198</td>\n",
       "      <td>3116.4</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>354107.28</td>\n",
       "      <td>6462246.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198</td>\n",
       "      <td>3116.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>354107.28</td>\n",
       "      <td>6462246.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198</td>\n",
       "      <td>3116.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>354107.28</td>\n",
       "      <td>6462246.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  well_name    DEPT   aps   rp     kp   kgl  kpr  kvo  kng  lit  satur    wc  \\\n",
       "0       198  3116.2  0.56  6.9  0.184  0.15  6.2  1.0  0.0  1.0    2.0  0.12   \n",
       "1       198  3116.3  0.56  6.9  0.184  0.15  6.2  1.0  0.0  1.0    2.0  0.12   \n",
       "2       198  3116.4  0.56  6.9  0.184  0.15  6.2  1.0  0.0  1.0    2.0  0.12   \n",
       "3       198  3116.5  0.56  6.9  0.184  0.15  6.2  1.0  0.0  1.0    2.0  0.12   \n",
       "4       198  3116.6  0.56  6.9  0.184  0.15  6.2  1.0  0.0  1.0    2.0  0.12   \n",
       "\n",
       "           x           y  \n",
       "0  354107.28  6462246.06  \n",
       "1  354107.28  6462246.06  \n",
       "2  354107.28  6462246.06  \n",
       "3  354107.28  6462246.06  \n",
       "4  354107.28  6462246.06  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import main\n",
    "las_data = pd.read_csv('las_data_cutted.csv', delimiter=';')\n",
    "las_data['well_name'] = las_data['well_name'].astype(str)\n",
    "las_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPT</th>\n",
       "      <th>aps</th>\n",
       "      <th>rp</th>\n",
       "      <th>kp</th>\n",
       "      <th>kgl</th>\n",
       "      <th>kpr</th>\n",
       "      <th>kvo</th>\n",
       "      <th>kng</th>\n",
       "      <th>lit</th>\n",
       "      <th>satur</th>\n",
       "      <th>wc</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2040</td>\n",
       "      <td>0</td>\n",
       "      <td>864</td>\n",
       "      <td>1078</td>\n",
       "      <td>930</td>\n",
       "      <td>1078</td>\n",
       "      <td>930</td>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>584</td>\n",
       "      <td>0</td>\n",
       "      <td>494</td>\n",
       "      <td>494</td>\n",
       "      <td>494</td>\n",
       "      <td>494</td>\n",
       "      <td>494</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>580</td>\n",
       "      <td>0</td>\n",
       "      <td>536</td>\n",
       "      <td>536</td>\n",
       "      <td>536</td>\n",
       "      <td>536</td>\n",
       "      <td>536</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>3526</td>\n",
       "      <td>0</td>\n",
       "      <td>1784</td>\n",
       "      <td>1780</td>\n",
       "      <td>1784</td>\n",
       "      <td>1784</td>\n",
       "      <td>1720</td>\n",
       "      <td>3526</td>\n",
       "      <td>3526</td>\n",
       "      <td>3526</td>\n",
       "      <td>3526</td>\n",
       "      <td>3526</td>\n",
       "      <td>3526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DEPT  aps    rp    kp   kgl   kpr   kvo   kng   lit  satur    wc  \\\n",
       "well_name                                                                     \n",
       "240        2040    0   864  1078   930  1078   930  2040  2040   2040  2040   \n",
       "303         584    0   494   494   494   494   494   584   584    584   584   \n",
       "304         580    0   536   536   536   536   536   580   580    580   580   \n",
       "306         566    0   512   512   512   512   512   566   566    566   566   \n",
       "307        3526    0  1784  1780  1784  1784  1720  3526  3526   3526  3526   \n",
       "\n",
       "              x     y  \n",
       "well_name              \n",
       "240        2040  2040  \n",
       "303         584   584  \n",
       "304         580   580  \n",
       "306         566   566  \n",
       "307        3526  3526  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_info = las_data.groupby('well_name').count()\n",
    "wells_without_aps = ld_info[ld_info['aps']<=0]\n",
    "wells_without_aps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['240', '303', '304', '306', '307', '308', '310', '311', '313',\n",
       "       '314', '316', '317', '318', '325', '327', '337', '341', '345',\n",
       "       '347', '354', '355', '361', '363', '364', '366', '370', '372',\n",
       "       '375', '378'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells_0 = wells_without_aps.index.values\n",
    "wells_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем в которых нет aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for well in  wells_0:\n",
    "    las_data = las_data.drop(las_data[las_data['well_name'] == well].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPT</th>\n",
       "      <th>aps</th>\n",
       "      <th>rp</th>\n",
       "      <th>kp</th>\n",
       "      <th>kgl</th>\n",
       "      <th>kpr</th>\n",
       "      <th>kvo</th>\n",
       "      <th>kng</th>\n",
       "      <th>lit</th>\n",
       "      <th>satur</th>\n",
       "      <th>wc</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>530</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.869811</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.607547</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.607547</td>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>555</td>\n",
       "      <td>0.827027</td>\n",
       "      <td>0.814414</td>\n",
       "      <td>0.827027</td>\n",
       "      <td>0.695495</td>\n",
       "      <td>0.827027</td>\n",
       "      <td>0.695495</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>476</td>\n",
       "      <td>0.886555</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.886555</td>\n",
       "      <td>0.743697</td>\n",
       "      <td>0.886555</td>\n",
       "      <td>0.743697</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>606</td>\n",
       "      <td>0.765677</td>\n",
       "      <td>0.739274</td>\n",
       "      <td>0.765677</td>\n",
       "      <td>0.620462</td>\n",
       "      <td>0.765677</td>\n",
       "      <td>0.620462</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>760</td>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.636842</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.415789</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.415789</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DEPT       aps        rp        kp       kgl       kpr       kvo  \\\n",
       "well_name                                                                     \n",
       "100         530  0.886792  0.869811  0.886792  0.607547  0.886792  0.607547   \n",
       "101         555  0.827027  0.814414  0.827027  0.695495  0.827027  0.695495   \n",
       "104         476  0.886555  0.848739  0.886555  0.743697  0.886555  0.743697   \n",
       "105         606  0.765677  0.739274  0.765677  0.620462  0.765677  0.620462   \n",
       "107         760  0.284211  0.636842  0.700000  0.415789  0.700000  0.415789   \n",
       "\n",
       "           kng  lit  satur   wc    x    y  \n",
       "well_name                                  \n",
       "100        530  530    530  530  530  530  \n",
       "101        555  555    555  555  555  555  \n",
       "104        476  476    476  476  476  476  \n",
       "105        606  606    606  606  606  606  \n",
       "107        760  760    760  760  760  760  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_info = las_data.groupby('well_name').count()\n",
    "ld_info.reset_index()\n",
    "ld_info[\"aps\"] = ld_info['aps']/ld_info['DEPT']\n",
    "ld_info[\"rp\"] = ld_info['rp']/ld_info['DEPT']\n",
    "ld_info[\"kp\"] = ld_info['kp']/ld_info['DEPT']\n",
    "ld_info[\"kgl\"] = ld_info['kgl']/ld_info['DEPT']\n",
    "ld_info[\"kpr\"] = ld_info['kpr']/ld_info['DEPT']\n",
    "ld_info[\"kvo\"] = ld_info['kvo']/ld_info['DEPT']\n",
    "ld_info. head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "well_name     0.000000\n",
       "DEPT          0.000000\n",
       "aps          36.065904\n",
       "rp           35.658689\n",
       "kp           35.435310\n",
       "kgl          38.356573\n",
       "kpr          35.315297\n",
       "kvo          38.356573\n",
       "kng           0.000000\n",
       "lit           0.000000\n",
       "satur         0.000000\n",
       "wc            0.000000\n",
       "x             0.000000\n",
       "y             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_count = las_data.count().max()\n",
    "hhh = 100 * las_data.isnull().sum()/rows_count\n",
    "hhh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оставляем только с литологией. так как для остальных значений кривые не пишут. видимо нет смысла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_data = las_data.drop(las_data[las_data['lit'] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "well_name     0.000000\n",
       "DEPT          0.000000\n",
       "aps           0.607340\n",
       "rp            1.431587\n",
       "kp            0.156173\n",
       "kgl          12.678948\n",
       "kpr           0.000000\n",
       "kvo          12.678948\n",
       "kng           0.000000\n",
       "lit           0.000000\n",
       "satur         0.000000\n",
       "wc            0.000000\n",
       "x             0.000000\n",
       "y             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_count = las_data.count().max()\n",
    "hhh = 100 * las_data.isnull().sum()/rows_count\n",
    "hhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "well_name      0.000000\n",
       "DEPT           0.000000\n",
       "aps            0.000000\n",
       "rp            11.291058\n",
       "kp             0.000000\n",
       "kgl          100.000000\n",
       "kpr            0.000000\n",
       "kvo          100.000000\n",
       "kng            0.000000\n",
       "lit            0.000000\n",
       "satur          0.000000\n",
       "wc             0.000000\n",
       "x              0.000000\n",
       "y              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_data = las_data[las_data['kgl'].isnull()]\n",
    "nan_list = np.unique(nan_data['well_name'].values).tolist()\n",
    "print(len(nan_list))\n",
    "\n",
    "rows_count = nan_data.count().max()\n",
    "hhh = 100 * nan_data.isnull().sum()/rows_count\n",
    "hhh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем в которых нет kgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for well in  nan_list:\n",
    "    las_data = las_data.drop(las_data[las_data['well_name'] == well].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "well_name    0.0\n",
       "DEPT         0.0\n",
       "aps          0.0\n",
       "rp           0.0\n",
       "kp           0.0\n",
       "kgl          0.0\n",
       "kpr          0.0\n",
       "kvo          0.0\n",
       "kng          0.0\n",
       "lit          0.0\n",
       "satur        0.0\n",
       "wc           0.0\n",
       "x            0.0\n",
       "y            0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_count = las_data.count().max()\n",
    "hhh = 100 * las_data.isnull().sum()/rows_count\n",
    "hhh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось скважин с \"хорошими\" данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "wells_list = las_data['well_name'].value_counts().index.tolist()\n",
    "print(len(wells_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "максимальное и минимальное количество строк на скважину. Минимум возмеме как размерность сжатия(усреднения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "1452\n"
     ]
    }
   ],
   "source": [
    "print(las_data.groupby('well_name').count().min().min())\n",
    "print(las_data.groupby('well_name').count().max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "needed_cols = ['aps', 'rp', 'kp', 'kgl', 'kpr', 'kvo', 'kng', 'satur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aps</th>\n",
       "      <th>rp</th>\n",
       "      <th>kp</th>\n",
       "      <th>kgl</th>\n",
       "      <th>kpr</th>\n",
       "      <th>kvo</th>\n",
       "      <th>kng</th>\n",
       "      <th>satur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.734937</td>\n",
       "      <td>7.136433</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>0.116411</td>\n",
       "      <td>9.156297</td>\n",
       "      <td>0.464762</td>\n",
       "      <td>0.237706</td>\n",
       "      <td>4.737174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.180975</td>\n",
       "      <td>3.848797</td>\n",
       "      <td>0.024556</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>25.464774</td>\n",
       "      <td>0.101995</td>\n",
       "      <td>0.265560</td>\n",
       "      <td>3.076714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.600000</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>376.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                aps            rp            kp           kgl           kpr  \\\n",
       "count  25378.000000  25378.000000  25378.000000  25378.000000  25378.000000   \n",
       "mean       0.734937      7.136433      0.148451      0.116411      9.156297   \n",
       "std        0.180975      3.848797      0.024556      0.052948     25.464774   \n",
       "min        0.250000      0.300000      0.060000      0.041000      0.100000   \n",
       "25%        0.600000      4.400000      0.131000      0.073000      1.900000   \n",
       "50%        0.750000      5.700000      0.145000      0.109000      3.800000   \n",
       "75%        0.880000      9.100000      0.158000      0.151000      7.900000   \n",
       "max        1.000000     72.600000      0.257000      0.299000    376.400000   \n",
       "\n",
       "                kvo           kng         satur  \n",
       "count  25378.000000  25378.000000  25378.000000  \n",
       "mean       0.464762      0.237706      4.737174  \n",
       "std        0.101995      0.265560      3.076714  \n",
       "min        0.204000      0.000000      0.000000  \n",
       "25%        0.404000      0.000000      2.000000  \n",
       "50%        0.444000      0.000000      2.000000  \n",
       "75%        0.517000      0.511000      8.000000  \n",
       "max        1.000000      0.796000     10.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_info = las_data[needed_cols]\n",
    "data_for_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\M1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\M1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aps</th>\n",
       "      <th>rp</th>\n",
       "      <th>kp</th>\n",
       "      <th>kgl</th>\n",
       "      <th>kpr</th>\n",
       "      <th>kvo</th>\n",
       "      <th>kng</th>\n",
       "      <th>satur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "      <td>25378.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.734937</td>\n",
       "      <td>0.098298</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>0.116411</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.464762</td>\n",
       "      <td>0.237706</td>\n",
       "      <td>0.473717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.180975</td>\n",
       "      <td>0.053014</td>\n",
       "      <td>0.024556</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.067653</td>\n",
       "      <td>0.101995</td>\n",
       "      <td>0.265560</td>\n",
       "      <td>0.307671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.078512</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.125344</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.020988</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                aps            rp            kp           kgl           kpr  \\\n",
       "count  25378.000000  25378.000000  25378.000000  25378.000000  25378.000000   \n",
       "mean       0.734937      0.098298      0.148451      0.116411      0.024326   \n",
       "std        0.180975      0.053014      0.024556      0.052948      0.067653   \n",
       "min        0.250000      0.004132      0.060000      0.041000      0.000266   \n",
       "25%        0.600000      0.060606      0.131000      0.073000      0.005048   \n",
       "50%        0.750000      0.078512      0.145000      0.109000      0.010096   \n",
       "75%        0.880000      0.125344      0.158000      0.151000      0.020988   \n",
       "max        1.000000      1.000000      0.257000      0.299000      1.000000   \n",
       "\n",
       "                kvo           kng         satur  \n",
       "count  25378.000000  25378.000000  25378.000000  \n",
       "mean       0.464762      0.237706      0.473717  \n",
       "std        0.101995      0.265560      0.307671  \n",
       "min        0.204000      0.000000      0.000000  \n",
       "25%        0.404000      0.000000      0.200000  \n",
       "50%        0.444000      0.000000      0.200000  \n",
       "75%        0.517000      0.511000      0.800000  \n",
       "max        1.000000      0.796000      1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_info['rp'] = data_for_info['rp']/data_for_info['rp'].max()\n",
    "data_for_info['kpr'] = data_for_info['kpr']/data_for_info['kpr'].max()\n",
    "data_for_info['satur'] = data_for_info['satur']/data_for_info['satur'].max()\n",
    "data_for_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_vector(df, vector_dim, cols):\n",
    "    cnt = int(len(df)/vector_dim)\n",
    "    edge_cnt = int(len(df)-(cnt*vector_dim))\n",
    "    res_vec = []\n",
    "    for col in cols:\n",
    "        n = 0\n",
    "        val = 0\n",
    "        is_first = True\n",
    "        for i in range(0,len(df)-1):\n",
    "            val = val + df.iloc[i][col]\n",
    "            n += 1\n",
    "            if n >= edge_cnt and is_first:\n",
    "                res_vec.append(val/n)\n",
    "                val = 0\n",
    "                n = 0\n",
    "                is_first=False\n",
    "            if n >= cnt and is_first== False:\n",
    "                res_vec.append(val/n)\n",
    "                val = 0\n",
    "                n = 0\n",
    "            else:\n",
    "                if i == len(df)-1:\n",
    "                    if n==0:\n",
    "                        n=1\n",
    "                    res_vec.append(val/n)\n",
    "                    val = 0\n",
    "                    n = 0\n",
    "    res_vec1 = np.array(res_vec)            \n",
    "    return res_vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "for well in wells_list:\n",
    "    well_data = las_data[las_data['well_name']==well]    \n",
    "    x_elem = get_x_vector(well_data[needed_cols], 62, needed_cols)\n",
    "    y_elem = well_data.iloc[0]['wc']\n",
    "    x_data.append(x_elem)\n",
    "    y_data.append(y_elem)\n",
    "#     cnt = int(len(df)/vector_dim)\n",
    "#     print(len(well_data[needed_cols]), len(x_elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 496)\n",
      "(98,)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(x_data)\n",
    "print(x_data.shape)\n",
    "y_data = np.array(y_data)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "x_train, x_hold, y_train, y_hold = train_test_split(x_data, y_data, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               63616     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 63,745\n",
      "Trainable params: 63,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Устанавливаем seed для повторяемости результатов\n",
    "np.random.seed(42)\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Компилируем модель\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M1\\Anaconda3\\lib\\site-packages\\keras\\models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 49.1580 - mean_absolute_error: 4.2731\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 81.9537 - mean_absolute_error: 5.0179\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 23.9743 - mean_absolute_error: 2.8775\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 3.5676 - mean_absolute_error: 1.1229\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32.1819 - mean_absolute_error: 2.2896\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 136.2584 - mean_absolute_error: 4.1354\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 69.5300 - mean_absolute_error: 3.9192\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 7.3809 - mean_absolute_error: 1.3770\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.1683 - mean_absolute_error: 0.6287\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4227 - mean_absolute_error: 0.4685\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.2786 - mean_absolute_error: 0.3799\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1911 - mean_absolute_error: 0.3320\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1602 - mean_absolute_error: 0.2883\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1713 - mean_absolute_error: 0.3201\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.1594 - mean_absolute_error: 0.2994\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.1266 - mean_absolute_error: 0.2712\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.1052 - mean_absolute_error: 0.2430\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0992 - mean_absolute_error: 0.2203\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0888 - mean_absolute_error: 0.2209\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0884 - mean_absolute_error: 0.2201\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0972 - mean_absolute_error: 0.2392\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0757 - mean_absolute_error: 0.2003\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0631 - mean_absolute_error: 0.1899\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0815 - mean_absolute_error: 0.2075\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0826 - mean_absolute_error: 0.2124\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1264 - mean_absolute_error: 0.2321\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3308 - mean_absolute_error: 0.2713\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 2.5102 - mean_absolute_error: 0.7599\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8.9405 - mean_absolute_error: 1.5711\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 24.4728 - mean_absolute_error: 1.7535\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 8.1765 - mean_absolute_error: 1.4092\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 15.8374 - mean_absolute_error: 1.3760\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24.3541 - mean_absolute_error: 1.9793\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10.1699 - mean_absolute_error: 1.1000\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 2.3028 - mean_absolute_error: 0.5739\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3477 - mean_absolute_error: 0.3133\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.1021 - mean_absolute_error: 0.2162\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0624 - mean_absolute_error: 0.1949\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0555 - mean_absolute_error: 0.1876\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0446 - mean_absolute_error: 0.1663\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0412 - mean_absolute_error: 0.1574\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0391 - mean_absolute_error: 0.1520\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0384 - mean_absolute_error: 0.1504\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0351 - mean_absolute_error: 0.1461\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0337 - mean_absolute_error: 0.1377\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0295 - mean_absolute_error: 0.1342\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0291 - mean_absolute_error: 0.1319\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0285 - mean_absolute_error: 0.1294\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0266 - mean_absolute_error: 0.1271\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0261 - mean_absolute_error: 0.1252\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0271 - mean_absolute_error: 0.1287\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0250 - mean_absolute_error: 0.1268\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0276 - mean_absolute_error: 0.1246\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0339 - mean_absolute_error: 0.1274\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0553 - mean_absolute_error: 0.1438\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1193 - mean_absolute_error: 0.1884\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3098 - mean_absolute_error: 0.2358\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 1.0723 - mean_absolute_error: 0.3857\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 3.5395 - mean_absolute_error: 0.6010\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10.3729 - mean_absolute_error: 0.8341\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9.4897 - mean_absolute_error: 0.9043\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 3.3753 - mean_absolute_error: 0.9134\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.2630 - mean_absolute_error: 0.3133\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0485 - mean_absolute_error: 0.1749\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0423 - mean_absolute_error: 0.1660\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0400 - mean_absolute_error: 0.1622\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0394 - mean_absolute_error: 0.1608\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0350 - mean_absolute_error: 0.1552\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0367 - mean_absolute_error: 0.1552\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0349 - mean_absolute_error: 0.1523\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_absolute_error: 0.1496\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0472 - mean_absolute_error: 0.1535\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0757 - mean_absolute_error: 0.1774\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0744 - mean_absolute_error: 0.1673\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0987 - mean_absolute_error: 0.1724\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0903 - mean_absolute_error: 0.1696\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0385 - mean_absolute_error: 0.1484\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0288 - mean_absolute_error: 0.1385\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0261 - mean_absolute_error: 0.1318\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0249 - mean_absolute_error: 0.1251\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0253 - mean_absolute_error: 0.1279\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0241 - mean_absolute_error: 0.1231\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0214 - mean_absolute_error: 0.1179\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0195 - mean_absolute_error: 0.1138\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0227 - mean_absolute_error: 0.1183\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0197 - mean_absolute_error: 0.1087\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0224 - mean_absolute_error: 0.1105\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1279\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0328 - mean_absolute_error: 0.1171\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0471 - mean_absolute_error: 0.1246\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0809 - mean_absolute_error: 0.1345\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2938 - mean_absolute_error: 0.2658\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.9156 - mean_absolute_error: 0.3845\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 1.9828 - mean_absolute_error: 0.4166\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 2.5468 - mean_absolute_error: 0.3423\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3168 - mean_absolute_error: 0.2953\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0623 - mean_absolute_error: 0.1509\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0242 - mean_absolute_error: 0.1225\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0196 - mean_absolute_error: 0.1146\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0179 - mean_absolute_error: 0.1093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1143a278>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем сеть\n",
    "model.fit(x_train, y_train, batch_size=1, nb_epoch=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя абсолютная ошибка на тестовых данных: 0.20 \n"
     ]
    }
   ],
   "source": [
    "# Оцениваем качество обучения сети на тестовых данных\n",
    "mse, mae = model.evaluate(x_hold, y_hold, verbose=0)\n",
    "print(\"Средняя абсолютная ошибка на тестовых данных: %.2f \" % (mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "# Преобразуем метки в категории\n",
    "y1_train = y_train*10\n",
    "y1_hold = y_hold*10\n",
    "y1_train = np_utils.to_categorical(y1_train, 10)\n",
    "y1_hold = np_utils.to_categorical(y1_hold, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(496, input_dim=496, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\M1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"normal\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 496)               246512    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                4970      \n",
      "=================================================================\n",
      "Total params: 251,482\n",
      "Trainable params: 251,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(496, input_dim=496, init=\"normal\", activation='relu'))\n",
    "model.add(Dense(10, init=\"normal\", activation='softmax'))\n",
    "\n",
    "# Компилируем модель\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/68 [=================>............] - ETA: 0s - loss: 14.2439 - acc: 0.1163  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M1\\Anaconda3\\lib\\site-packages\\keras\\models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 4ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9848 - acc: 0.1324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1285b6d8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем сеть\n",
    "model.fit(x_train, y1_train, batch_size=1, nb_epoch=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность работы на тестовых данных: 10.00%\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем качество обучения сети на тестовых данных\n",
    "scores = model.evaluate(x_hold, y1_hold, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=20, random_state=17)\n",
    "tree.fit(x_train, y1_train)\n",
    "tree_pred = tree.predict(x_hold)\n",
    "accuracy_score(y1_hold, tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 145 | elapsed:    3.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=17,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': range(1, 30)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=True)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "count_vals = x_data.shape[1]\n",
    "print(count_vals)\n",
    "tree_params = {'max_depth': range(1,30)}\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1, verbose=True)\n",
    "tree_grid.fit(x_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7}\n",
      "0.264705882353\n",
      "0.133333333333\n"
     ]
    }
   ],
   "source": [
    "print(tree_grid.best_params_)\n",
    "print(tree_grid.best_score_)\n",
    "print(accuracy_score(y1_hold, tree_grid.predict(x_hold)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}